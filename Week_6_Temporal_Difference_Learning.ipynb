{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Week 6 Temporal Difference Learning",
      "provenance": [],
      "authorship_tag": "ABX9TyN1SwQvjNKwxH3dWYfTipDP",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/mcnica89/MATH4060/blob/main/Week_6_Temporal_Difference_Learning.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UnMnJvcFDlmG"
      },
      "outputs": [],
      "source": [
        "import itertools\n",
        "import jax.numpy as jnp\n",
        "import matplotlib.pyplot as plt\n",
        "from jax import random as jrandom\n",
        "from jax import nn as jnn\n",
        "from jax import jit\n",
        "import random\n",
        "import time\n",
        "import timeit\n",
        "import math\n",
        "import numpy as np\n",
        "\n",
        "plt.rc('xtick', labelsize=15) \n",
        "plt.rc('ytick', labelsize=15)\n",
        "font = {'size'   : 20}\n",
        "\n",
        "plt.rc('font', **font)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Gambler's Ruin (aka Drunkard's Walk)\n",
        "\n",
        "Consider the statespace $[[0,N_{target}]] \\subset \\mathbb{Z}$ which represetnt possible values for a gambler's wealth. Let $X_n$ be a Markov chain representing the Gambler's wealth after $n$ bets. If they have no money, $0$, then they cannot make any bets:\n",
        "\n",
        "$$P( X_{n+1} = 0 | X_n = 0) =1$$\n",
        "\n",
        "If they reach their target $N_{target}$, then they choose to stop gambling.\n",
        "\n",
        "\n",
        "$$P( X_{n+1} = N_{target} | X_n = N_{target}) =1$$\n",
        "\n",
        "Otherwise, they bet and their fortune goes up or down by exactly $1$:\n",
        "\n",
        "$$P( X_{n+1} = x+1 | X_n = x) =p$$\n",
        "$$P( X_{n+1} = x-1 | X_n = x) =1-p$$\n",
        "\n",
        "The gambler keeps playing until they either go broke or reach their target. Assume the Gambler gains a reward of 1 life point if they get to $N_{target}$ and the gain a reward of 0 if they reach their target. Determine\n",
        "\n",
        "$$E[\\text{Reward}|X_0 = x] = P(\\text{Reach target}|X_0 = x)$$\n"
      ],
      "metadata": {
        "id": "N46NjQCKD4AC"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Monte Carlo Method"
      ],
      "metadata": {
        "id": "qJ3cfgYWtDTe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def monte_carlo_method(learning_rate, N_episodes, N_target):\n",
        "  value_function = np.zeros(N_target+1)\n",
        "  num_visits = np.zeros(N_target+1)\n",
        "\n",
        "  for i in range(N_episodes):\n",
        "    x_0 = random.randint(1,N_target-1)\n",
        "    current_state = x_0\n",
        "\n",
        "    current_time = 0\n",
        "    max_time = 10*N_target**2\n",
        "    state_history = np.zeros(max_time+1,dtype=int)\n",
        "    reward_history = np.zeros(max_time+1)\n",
        "\n",
        "    while True: \n",
        "      state_history[current_time] = current_state\n",
        "      if current_state==0 or current_state==N_target or current_time >= max_time:\n",
        "        reward_history[current_time] = (current_state==N_target)\n",
        "        break\n",
        "      else:\n",
        "        reward_history[current_time] = 0   \n",
        "      \n",
        "      #THIS IS THE MOST IMPORTANT LINE OF PART I:\n",
        "      #current_state = gridworld_next_state(current_state,policy[current_state])\n",
        "      \n",
        "      current_state += 2*random.randint(0,1)-1\n",
        "      current_time += 1\n",
        "\n",
        "    t_final = current_time\n",
        "    \n",
        "    \n",
        "    #PART II\n",
        "    #Now update the value function for states we saw this episode\n",
        "    #We are using the first visit monte carlo rule!\n",
        "    \n",
        "    visited_already = np.zeros(N_target+1,dtype=bool)\n",
        "    for t in range(0,t_final+1):\n",
        "      state = state_history[t]\n",
        "      if visited_already[state] == False:\n",
        "        G = np.sum(reward_history[t:t_final+1])\n",
        "        num_visits[state] += 1\n",
        "        \n",
        "        #This line actually computes the AVERAGE of G over all the visits!\n",
        "        #Homework: Figure out why this line is actually computing the average!\n",
        "        #i..e value_function[state] will be = average of G's over all observations\n",
        "        value_function[state] += learning_rate*(G - value_function[state])\n",
        "                \n",
        "\n",
        "        visited_already[state] = True\n",
        "  \n",
        "  return value_function"
      ],
      "metadata": {
        "id": "zWRnWNlStZWu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "monte_carlo_method(0.05,100000, 10)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vVTM2tkez9eD",
        "outputId": "5912fe99-3541-4bf9-fcfe-ffe69bd98797"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0.  , 0.1 , 0.17, 0.19, 0.35, 0.42, 0.58, 0.72, 0.82, 0.91, 1.  ])"
            ]
          },
          "metadata": {},
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# TD0 Method (Temperal Difference Learning with 0 memory)"
      ],
      "metadata": {
        "id": "Swga9qT8s88k"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def TD0_method(learning_rate, N_samples, N_target):\n",
        "\n",
        "  #This code is very similar to the naive Monte Carlo method\n",
        "  #Instead of keeping track of total_rewards, we update the function V as we go\n",
        "\n",
        "  value_func = np.random.rand(N_target+1)\n",
        "  #Warning: initializing with value_func = all zeros will lead to worse performance!\n",
        "  #Ideally want them to be \"on average\" correct\n",
        "  \n",
        "  #This works too: value_func = 0.5*np.ones(N_target+1)\n",
        "  #This is bad: value_func = np.zeros(N_target+1)\n",
        "  value_func[N_target] = 1\n",
        "  value_func[0] = 0\n",
        "  \n",
        "  for i in range(N_samples):\n",
        "    x_0 = random.randint(1,N_target-1)\n",
        "    X = x_0\n",
        "    \n",
        "    while X > 0 and X < N_target:\n",
        "      new_X = X + 2*random.randint(0,1)-1\n",
        "      delta_value = value_func[new_X] - value_func[X]\n",
        "      value_func[X] += learning_rate*( delta_value  )\n",
        "      X = new_X\n",
        "\n",
        "  return value_func"
      ],
      "metadata": {
        "id": "br_rg8wGv-xk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "TD0_method(0.1, 100000, 10)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HtuWr6mZ1heA",
        "outputId": "ddf38bab-1c63-4272-b205-1049a554800f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0.  , 0.07, 0.17, 0.26, 0.37, 0.46, 0.58, 0.74, 0.82, 0.93, 1.  ])"
            ]
          },
          "metadata": {},
          "execution_count": 46
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Time comparisons"
      ],
      "metadata": {
        "id": "Sa7nl51f1xhE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def numpy_rms(x):\n",
        "  #Return the root-mean-square of a sequence\n",
        "  return np.sqrt(np.mean(np.square(x)))"
      ],
      "metadata": {
        "id": "F7d8QZM6Acc5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "N_target = 100\n",
        "N_samples = 5*10**3\n",
        "exact_answer = np.arange(0,N_target+1)/N_target\n",
        "np.set_printoptions(precision=2,suppress=True)"
      ],
      "metadata": {
        "id": "60o-gGkNA-ui"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%time val_MC = monte_carlo_method(0.1, N_samples, N_target)\n",
        "print(val_MC)\n",
        "print( numpy_rms(val_MC-exact_answer) )"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "w2HREgFv1w5k",
        "outputId": "552f6c9b-0842-460d-ba33-736058f0b2b8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CPU times: user 30.5 s, sys: 406 ms, total: 30.9 s\n",
            "Wall time: 30.5 s\n",
            "[0.   0.03 0.03 0.08 0.08 0.11 0.11 0.12 0.13 0.13 0.13 0.14 0.14 0.14\n",
            " 0.14 0.17 0.17 0.17 0.17 0.17 0.21 0.21 0.21 0.23 0.23 0.23 0.23 0.25\n",
            " 0.27 0.27 0.3  0.31 0.31 0.31 0.32 0.32 0.32 0.32 0.32 0.36 0.36 0.36\n",
            " 0.36 0.36 0.36 0.39 0.39 0.43 0.43 0.43 0.43 0.43 0.44 0.45 0.45 0.45\n",
            " 0.45 0.45 0.45 0.45 0.45 0.46 0.46 0.46 0.48 0.54 0.54 0.55 0.55 0.61\n",
            " 0.68 0.68 0.7  0.72 0.72 0.73 0.77 0.77 0.77 0.77 0.78 0.78 0.78 0.78\n",
            " 0.78 0.78 0.78 0.78 0.78 0.78 0.87 0.87 0.87 0.88 0.98 0.98 0.98 0.98\n",
            " 0.98 0.98 1.  ]\n",
            "0.06435515430893131\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%time val_TD0 = TD0_method(0.1, N_samples, N_target)\n",
        "print(val_TD0)\n",
        "print( numpy_rms(val_TD0-exact_answer) )"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FnoMFmpJ_HA1",
        "outputId": "30e482f9-96a4-400b-9f93-233e288a2958"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CPU times: user 17.6 s, sys: 23.8 ms, total: 17.6 s\n",
            "Wall time: 17.6 s\n",
            "[0.   0.   0.01 0.02 0.03 0.03 0.04 0.04 0.05 0.06 0.07 0.07 0.08 0.09\n",
            " 0.1  0.11 0.12 0.13 0.14 0.14 0.15 0.16 0.17 0.18 0.2  0.21 0.22 0.22\n",
            " 0.23 0.24 0.26 0.27 0.29 0.3  0.31 0.32 0.33 0.34 0.35 0.37 0.38 0.4\n",
            " 0.41 0.42 0.43 0.44 0.46 0.47 0.48 0.49 0.5  0.51 0.52 0.53 0.55 0.56\n",
            " 0.57 0.57 0.59 0.6  0.62 0.62 0.64 0.64 0.65 0.66 0.67 0.68 0.69 0.7\n",
            " 0.71 0.72 0.74 0.75 0.76 0.78 0.79 0.8  0.82 0.84 0.85 0.86 0.86 0.87\n",
            " 0.88 0.89 0.9  0.91 0.92 0.92 0.93 0.94 0.95 0.96 0.96 0.97 0.98 0.98\n",
            " 0.99 0.99 1.  ]\n",
            "0.028429865765165735\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%time TD0_method(0.01, 3000, 100)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "j_IYpof917vb",
        "outputId": "73427e5e-a00e-4048-fb2c-094baf0333c0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CPU times: user 11.1 s, sys: 25.7 ms, total: 11.2 s\n",
            "Wall time: 11.2 s\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0.  , 0.03, 0.06, 0.09, 0.12, 0.14, 0.17, 0.19, 0.21, 0.23, 0.25,\n",
              "       0.27, 0.29, 0.3 , 0.32, 0.33, 0.34, 0.36, 0.37, 0.38, 0.39, 0.39,\n",
              "       0.4 , 0.41, 0.42, 0.42, 0.43, 0.43, 0.44, 0.44, 0.45, 0.45, 0.45,\n",
              "       0.46, 0.46, 0.46, 0.46, 0.47, 0.47, 0.47, 0.47, 0.47, 0.48, 0.48,\n",
              "       0.48, 0.48, 0.48, 0.48, 0.49, 0.49, 0.49, 0.49, 0.49, 0.49, 0.5 ,\n",
              "       0.5 , 0.5 , 0.5 , 0.5 , 0.51, 0.51, 0.51, 0.51, 0.52, 0.52, 0.52,\n",
              "       0.53, 0.53, 0.53, 0.54, 0.54, 0.55, 0.55, 0.56, 0.57, 0.57, 0.58,\n",
              "       0.59, 0.59, 0.6 , 0.61, 0.62, 0.63, 0.64, 0.65, 0.66, 0.68, 0.69,\n",
              "       0.7 , 0.72, 0.74, 0.76, 0.78, 0.8 , 0.82, 0.85, 0.87, 0.9 , 0.93,\n",
              "       0.97, 1.  ])"
            ]
          },
          "metadata": {},
          "execution_count": 62
        }
      ]
    }
  ]
}